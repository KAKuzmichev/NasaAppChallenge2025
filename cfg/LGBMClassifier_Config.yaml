# LightGBM Classifier Configuration
# NASA Exoplanet Detection Challenge 2025

# Основні параметри керування навчанням (Core Parameters)
# Контролюють загальний процес навчання та функцію втрат
core_parameters:
  # Мета навчання (функція втрат)
  objective: 'binary'
  
  # Тип бустингу: gbdt (дерева градієнтного бустингу), dart, rf (випадковий ліс)
  boosting_type: 'gbdt'
  
  # Кількість бустингових ітерацій (дерев)
  n_estimators: 50
  
  # Швидкість навчання. Контролює розмір кроку на кожній ітерації
  learning_rate: 0.018
  
  # Кількість класів (для мультикласової класифікації)
  num_class: 1
  
  # Метрики для оцінки моделі, що використовуються для ранньої зупинки
  metric: 'binary_logloss'
  
  # Насіння для генератора випадкових чисел (для відтворюваності)
  seed: 123

# Параметри структури дерева та складності (Tree Parameters)
# Контролюють складність кожного дерева і є критичними для боротьби з перенавчанням
tree_parameters:
  # Максимальна кількість листків в одному дереві. Головний регулятор складності LightGBM
  num_leaves: 31
  
  # Максимальна глибина дерева. Використовується для обмеження росту дерева явним чином
  max_depth: -1
  
  # Мінімальна кількість об'єктів (зразків) у листі дерева
  min_child_samples: 25
  
  # Мінімальна сума Гессіанів (других похідних) у листі
  min_child_weight: 0.0001
  
  # Максимальна кількість сегментів (бінів), на які розділятимуться ознаки
  max_bin: 255

# Параметри вибірки та регуляризації (Sampling & Regularization)
# Допомагають моделі узагальнювати дані та зменшувати перенавчання
sampling_regularization:
  # Частка ознак, що випадковим чином обирається для побудови кожного дерева
  feature_fraction: 0.8
  
  # Частка даних, що випадковим чином обирається для побудови кожного дерева (вибірка рядків)
  bagging_fraction: 0.8
  
  # Частота виконання беггінгу
  bagging_freq: 1
  
  # Коефіцієнт L1-регуляризації
  lambda_l1: 0.1
  
  # Коефіцієнт L2-регуляризації
  lambda_l2: 0.1
  
  # Мінімальний виграш (gain) для виконання поділу у вузлі
  min_gain_to_split: 0.0

# Параметри продуктивності та оптимізації (Performance & Optimization)
# Впливають на швидкість навчання та обробку спеціальних випадків
performance_optimization:
  # Кількість потоків (ядер процесора) для навчання
  n_jobs: -1
  
  # Використовувати CPU або GPU для прискорення
  device: 'cpu'  # 'cpu' або 'gpu'
  
  # Виводить інформацію під час навчання
  verbose: 1
  
  # Тип паралельного навчання дерев
  tree_learner: 'data'  # 'serial', 'feature', 'data', 'voting'
  
  # Коефіцієнт для масштабування позитивного класу (для незбалансованих бінарних даних)
  scale_pos_weight: 1.0

# Альтернативні конфігурації для різних сценаріїв
configurations:
  # Швидке навчання (менша точність, більша швидкість)
  fast_training:
    n_estimators: 30
    learning_rate: 0.1
    num_leaves: 15
    min_child_samples: 50
    
  # Високоточне навчання (більша точність, повільніше)
  high_accuracy:
    n_estimators: 200
    learning_rate: 0.01
    num_leaves: 63
    min_child_samples: 10
    feature_fraction: 0.9
    bagging_fraction: 0.9
    
  # Для великих датасетів
  large_dataset:
    n_estimators: 100
    learning_rate: 0.05
    num_leaves: 127
    max_bin: 512
    feature_fraction: 0.7
    bagging_fraction: 0.7
    
  # GPU оптимізована конфігурація
  gpu_optimized:
    device: 'gpu'
    tree_learner: 'data'
    num_leaves: 255
    max_bin: 1023